### Authors

-   Emanuele Massoglia
-   Jakov Tushevski
-   Gabriel Haas

# DOCUMENTATION

This document describes a software for protein function prediction using results from a deep learning pipeline for predicting protein functions.

## Software

The inference pipeline is designed to ensure both high performance and robustness. The core logic is encapsulated within the `CAFA_predictor` class (located in `src/predictor.py`) which uses deep learning inference.

**Deep Learning Inference**\
If the protein is not found in the cache, the system falls back to trained neural network models (TensorFlow/Keras).\
Input features are preprocessed and scaled using saved metadata, and predictions are generated by the ontology-specific classifiers.

### Prediction Policy

Predictions are generated independently for each ontology (Molecular Function, Biological Process, Cellular Component).

For each protein, Gene Ontology (GO) terms are ranked by predicted probability, and the **top 500 terms per ontology** are retained.\
This ranking-based strategy aligns with the CAFA evaluation protocol and avoids hard thresholding, while respecting the maximum limit of **1500 total predictions per protein**.

All predicted confidence scores are strictly greater than zero.\
To comply with CAFA submission requirements, predicted probabilities are clipped to a minimum value of **1e-6** when necessary.

This architecture ensures a robust and reproducible software solution capable of handling both known proteins and novel sequences represented by precomputed features.

------------------------------------------------------------------------

## Installation and requirements

The software requires Python 3.8 or higher. It relies on standard bioinformatics and machine learning libraries. Dependencies: Ensure the following packages are installed (installable via pip install -r requirements.txt):

-   **tensorflow** – loading and executing neural network models\
-   **numpy, pandas** – data manipulation and numerical computation\
-   **scikit-learn** – feature scaling and preprocessing\
-   **biopython** – sequence handling utilities (not used for inference)

## Configuration

To ensure modularity and reproducibility, no hard-coded paths are used within the source code. All operational parameters are defined in the external config.json file:

Main configuration sections include:

-   **models**: Paths to trained `.h5` models for MF, BP, and CC\
-   **metadata**: Paths to scalers and Gene Ontology mapping files (`.pkl`), and to test_ids\
-   **cache**: Optional paths to precomputed prediction files\
-   **settings**: Global parameters such as `top_k` and output directories

## Command-Line Interface

The software provides a Command Line Interface (CLI) implemented via the argparse module, making it easy to integrate into larger bioinformatics pipelines.

### Running Predictions (main.py)

To generate predictions for a new dataset, execute the main.py script. The software automatically handles data loading, preprocessing, inference, and result formatting. FO executing you need to type the following commands in your terminal after having set the directory in which the software is saved as the current directory:

python main.py -i <INPUT_FILE> [-o <OUTPUT_FILE>] [-c <CONFIG_FILE>]

Example:

python main.py -i data/test/X_test.npy -o results/final_predictions.csv
