{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b86249c-0f8e-41ea-a0b8-c3e9b514b92e",
   "metadata": {},
   "source": [
    "# Cellular Component GO term prediction\n",
    "This notebook implements the trained CC prediction model on the test dataset and outputs final CC term predictions as a csv or text file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5373d55-3cca-41a6-9ecd-0eebc10022a1",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f3663a-de10-4359-9161-da9f19f050e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bfdb79-5501-4ba5-a4f8-6f12aa6910e0",
   "metadata": {},
   "source": [
    "### 2. Setup\n",
    "Artifacts are reused without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ef7c3e-1b5d-4bcd-8a0b-80062937096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining paths\n",
    "meta_dir       = \"metadata/CC\"\n",
    "CC_model_path  = \"metadata/CC/cc_model.h5\"\n",
    "test_dir       = \"data/test\"\n",
    "\n",
    "x_test_path    = os.path.join(test_dir,  \"X_test.npy\")\n",
    "test_ids_path  = os.path.join(test_dir, \"test_ids.txt\")\n",
    "scaler_path    = os.path.join(meta_dir, \"embed_scaler.pkl\")\n",
    "pred_out_csv   = os.path.join(meta_dir, \"cc_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eea499a-7ddf-4a21-b3d6-50fdebba9f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = 8.0  # must match training value\n",
    "\n",
    "def weighted_bce(y_true, y_pred):\n",
    "    bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "    weights = y_true * pos_weight + (1.0 - y_true)\n",
    "    return tf.reduce_mean(weights * bce)\n",
    "\n",
    "# loading model\n",
    "model = tf.keras.models.load_model(\n",
    "    CC_model_path,\n",
    "    custom_objects={\"weighted_bce\": weighted_bce}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c6716b-cb9c-4047-a8c1-940cc556c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test data\n",
    "X_test = np.load(x_test_path)\n",
    "\n",
    "# checking and loading test_ids\n",
    "if os.path.exists(test_ids_path):\n",
    "    with open(test_ids_path, \"r\") as f:\n",
    "        test_ids = [line.strip() for line in f if line.strip()]\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Could not find test IDs at: {test_ids_path}\")\n",
    "\n",
    "assert len(test_ids) == X_test.shape[0], \"Mismatch: number of test_ids != rows in X_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6426e9-9a01-46fd-a4e4-355f3bfe04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading metadata\n",
    "\n",
    "cc_keep = np.load(f\"{meta_dir}/go_terms.npy\", allow_pickle=True)\n",
    "with open(f\"{meta_dir}/go_map.pkl\", \"rb\") as f:\n",
    "    go_cc_map = pickle.load(f)\n",
    "\n",
    "# inverse mapping column index to GO term\n",
    "inv_go_cc_map = {v: k for k, v in go_cc_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bca88b-4c5c-4709-b523-3558b5f9fa0d",
   "metadata": {},
   "source": [
    "### 3. Test feature normalization, same as training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a8236c-5660-4306-abfe-5a6b899503ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data normalization\n",
    "\n",
    "# loading scaler\n",
    "with open(scaler_path, \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Separating InterPro and ProtT5 features exactly as in training\n",
    "interpro_dim = 1000\n",
    "Xtest_domains = X_test[:, :interpro_dim].astype(np.float32)\n",
    "Xtest_embed   = X_test[:, interpro_dim:].astype(np.float32)\n",
    "\n",
    "# Scaling\n",
    "Xtest_embed_scaled = scaler.transform(Xtest_embed)\n",
    "\n",
    "# Recombining\n",
    "X_test_scaled = np.concatenate(\n",
    "    [Xtest_domains, Xtest_embed_scaled],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090d84a-5bd7-4d7a-a2c4-de4f117193da",
   "metadata": {},
   "source": [
    "### 4. Running the model and recording the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab608612-b824-4c0a-a362-aa011f1e9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "test_probs = model.predict(X_test_scaled, batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972d3c44-a366-4df6-bfec-f4761ae13179",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_protein_terms = 500   # cap of terms per sub-ontology per protein\n",
    "THR = 0.4\n",
    "\n",
    "rows = []\n",
    "for i, pid in enumerate(test_ids):\n",
    "    probs = test_probs[i]\n",
    "\n",
    "    # candidate indices above threshold\n",
    "    idx = np.where(probs >= THR)[0]\n",
    "\n",
    "    # if none are above the threshold, output the top few\n",
    "    if idx.size == 0:\n",
    "        idx = np.argsort(-probs)[:10]\n",
    "\n",
    "    # sort by probability\n",
    "    idx = idx[np.argsort(-probs[idx])][:max_protein_terms]\n",
    "\n",
    "    for j in idx:\n",
    "        go = inv_go_cc_map[int(j)]\n",
    "        score = float(probs[j])\n",
    "\n",
    "        # enforce (0, 1.000] and avoid 0\n",
    "        if score <= 0.0:\n",
    "            continue\n",
    "        if score > 1.0:\n",
    "            score = 1.0\n",
    "\n",
    "        # format to 3 significant figures\n",
    "        score_str = f\"{score:.3g}\"\n",
    "        rows.append((pid, go, score_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f0381a-c384-4f2f-af03-e278f2306fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: metadata/CC\\cc_predictions.csv rows: 29642\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(rows, columns=[\"Protein_ID\", \"GO_term\", \"score\"])\n",
    "pred_df.to_csv(pred_out_csv, index=False)\n",
    "print(\"Saved:\", pred_out_csv, \"rows:\", len(pred_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "703a0c8d-99e0-4479-bbac-24f985b0b007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: metadata/CC\\cc_submission.txt\n"
     ]
    }
   ],
   "source": [
    "submission_txt = os.path.join(meta_dir, \"cc_submission.txt\")\n",
    "with open(submission_txt, \"w\") as f:\n",
    "    for pid, go, score_str in rows:\n",
    "        f.write(f\"{pid}\\t{go}\\t{score_str}\\n\")\n",
    "print(\"Saved:\", submission_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_model",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
